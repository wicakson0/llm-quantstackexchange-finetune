{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b11d858c",
   "metadata": {},
   "source": [
    "# Fine-Tuning TinyLlama_v1.1_math_code on Quantitative Finance StackExchange Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68728e0",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aad1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "import mlflow\n",
    "import os\n",
    "from huggingface_hub import HfApi, Repository, create_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b0d5c",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# override default Huggingface Cache Location (C: drive)\n",
    "os.environ['HF_HUB_CACHE'] = 'models/.HF_HUB_CACHE'\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd861c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 7\n",
    "TRAIN_PROP_1 = 0.9\n",
    "TRAIN_PROP_2 = 0.9\n",
    "NUM_EPOCH = 5\n",
    "BATCH_SIZE = 32\n",
    "# GRAD_ACCUMULATE = 1\n",
    "MAX_TOKEN_LENGTH = 512\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7be962",
   "metadata": {},
   "source": [
    "## Clean and Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ffa2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE = load_dataset('theblackcat102/quant-stackexchange-posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE.set_format(type='pandas')\n",
    "quant_SE_df = quant_SE['train'][:]\n",
    "quant_SE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19c745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_df.to_csv('data/raw/theblackcat102-quant-stackexchange-posts.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287dd50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_left = quant_SE_df.loc[:,[\"AcceptedAnswerId\", \"ParentId\",\"Title\", \"Body\", \"Score\"]]\n",
    "quant_SE_left = quant_SE_left.rename(columns={\"Body\": \"Answer\"})\n",
    "quant_SE_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_right = quant_SE_df.loc[:,[\"Id\", \"Body\"]]\n",
    "quant_SE_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_right = quant_SE_right.rename(columns={\"Body\": \"Question\"})\n",
    "quant_SE_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23bc9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean = quant_SE_left.merge(quant_SE_right, left_on=\"AcceptedAnswerId\", right_on=\"Id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03addb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db687105",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean.Score = pd.to_numeric(quant_SE_clean.Score, downcast='integer')\n",
    "quant_SE_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b5dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean = quant_SE_clean.loc[quant_SE_clean[\"Score\"] >= 0,:]\n",
    "quant_SE_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean[\"text\"] = quant_SE_clean[\"Title\"].str.cat(quant_SE_clean[\"Question\"], sep=' ', na_rep='')\n",
    "quant_SE_clean[\"text\"] = quant_SE_clean[\"text\"].str.cat(quant_SE_clean[\"Answer\"], sep=' ', na_rep='')\n",
    "quant_SE_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d94492",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean = quant_SE_clean.loc[:,\"text\"]\n",
    "quant_SE_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dda912",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(quant_SE_clean, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b17b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean = pd.DataFrame(quant_SE_clean)\n",
    "quant_SE_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d1a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean = quant_SE_clean.dropna()\n",
    "quant_SE_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84eb5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a52250",
   "metadata": {},
   "source": [
    "## Training-Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5d6045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean_train, quant_SE_clean_test = train_test_split(\n",
    "    quant_SE_clean,\n",
    "    random_state = RANDOM_STATE,\n",
    "    train_size = TRAIN_PROP_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23e144e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean_training, quant_SE_clean_validation = train_test_split(\n",
    "    quant_SE_clean_train,\n",
    "    random_state = RANDOM_STATE,\n",
    "    train_size = TRAIN_PROP_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ffaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab55806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1aff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c7409",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4866bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_clean_training.to_csv('data/prepped/quant_SE_clean_training.csv', index=False)\n",
    "quant_SE_clean_validation.to_csv('data/prepped/quant_SE_clean_validation.csv', index=False)\n",
    "quant_SE_clean_test.to_csv('data/prepped/quant_SE_clean_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0a49f",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5634aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"TinyLlama/TinyLlama_v1.1_math_code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6856bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a94675",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84868dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c8bd57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], return_tensors=\"pt\", truncation=True, padding=\"max_length\", return_overflowing_tokens=True, max_length=MAX_TOKEN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_training = load_dataset('csv', data_files=\"data/prepped/quant_SE_clean_training.csv\")\n",
    "quant_SE_validation = load_dataset('csv', data_files=\"data/prepped/quant_SE_clean_validation.csv\")\n",
    "quant_SE_test = load_dataset('csv', data_files=\"data/prepped/quant_SE_clean_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8205711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_dataset = DatasetDict({\n",
    "    'train': quant_SE_training['train'],\n",
    "    'validation': quant_SE_validation['train'],\n",
    "    'test': quant_SE_test['train']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be63c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a7ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_tokenized = quant_SE_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c44494",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_SE_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2ae0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models\",                      # Where to save the model\n",
    "    num_train_epochs=NUM_EPOCH,               # Total number of epochs\n",
    "    learning_rate=2e-5,                       # Fine-tuned learning rate\n",
    "    per_device_train_batch_size=BATCH_SIZE,   # Batch size per GPU for training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,    # Batch size per GPU for evaluation\n",
    "    weight_decay=0.01,                        # Regularization to prevent overfitting\n",
    "    eval_strategy=\"steps\",                    # Evaluate every `eval_steps`\n",
    "    eval_steps=500,                           # Evaluate every 500 steps\n",
    "    save_strategy=\"steps\",                    # Save model every `save_steps`\n",
    "    save_steps=500,                           # Save model every 500 steps\n",
    "    save_total_limit=2,                       # Keep only the last 2 saved models\n",
    "    logging_steps=100,                        # Log every 100 steps\n",
    "    warmup_steps=500,                         # Warmup steps for learning rate scheduler\n",
    "    load_best_model_at_end=True,              # Load the best model at the end\n",
    "    greater_is_better=True,                   # Best model is based on higher metric values\n",
    "    fp16=True,                                # Enable mixed precision training for faster computation\n",
    "    report_to=\"mlflow\",                       # Report training metrics to MLflow\n",
    "    push_to_hub=True,                         # Push the model to Hugging Face Hub\n",
    "    hub_model_id=\"wicakson0/TinyLlama_v1.1_math_code_finetuned_quant_SE\", # Hugging Face model ID\n",
    "    hub_token=os.getenv(\"HF_TOKEN\"),          # Hugging Face authentication token\n",
    "    logging_dir=\"logs\",                     # Directory to store logs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c918b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:///E:/Current_Workdir/llm-quantstackexchange-finetune/report\")  # Replace with your MLflow tracking directory path\n",
    "mlflow.set_experiment(\"TinyLlama_v1.1_math_code_finetuned_quant_SE\")  # Experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d860de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # Causal LM: MLM (Masked Language Modeling) is set to False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a27e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=quant_SE_tokenized['train'],\n",
    "    eval_dataset=quant_SE_tokenized['validation'],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02687eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del quant_SE_training, quant_SE_validation, quant_SE_test\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac325a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70773b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"model/finetuned_model\")\n",
    "tokenizer.save_pretrained(\"model/finetuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da852e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(commit_message=\"Fine-tuned TinyLlama/TinyLlama_v1.1_math_code using cleaned theblackcat102/quant-stackexchange-posts\", \n",
    "                    blocking=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
